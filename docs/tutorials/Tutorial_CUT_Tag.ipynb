{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23a8640-4fc7-4f0f-9fc5-8fa5b0b2e4d3",
   "metadata": {},
   "source": [
    "# SPEED workflow : Training on the spatial epigenomic data without prior information from single-cell data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324d8a5-1ffa-4357-beb5-fd61801ff9b8",
   "metadata": {},
   "source": [
    "Dataset: The E13 mouse embryo spatial CUT&Tag-RNA-seq dataset by Zhang et al ([here](https://doi.org/10.5281/zenodo.14948507))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6961de-7e28-4d53-bb1a-2c28ac07e10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whether GPU is detected: True\n",
      "CUDA version: 11.7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Whether GPU is detected:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb97dfd6-c9e6-4197-ad76-e5b74585c211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import SPEED\n",
    "import scanpy as sc\n",
    "\n",
    "adata_input_path = 'spCUT_Tag/tile_H3K27ac.h5ad'\n",
    "adata_output_path = './H3K27ac_out'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec578cdb-f297-49a7-a085-bf2f08b1b317",
   "metadata": {},
   "source": [
    "load the spatial epigenomic data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6495d-5b5e-452d-87fc-f43dc43a7cad",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f34540-f197-49d6-ac74-d5cd2c5466c5",
   "metadata": {},
   "source": [
    "Load the spatial epigenomic data without the corresponding single-cell data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19edfffd-0e7a-4e44-a5fa-bb14cc096656",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(adata_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e317f49-5be8-49de-b9ac-5252936abef0",
   "metadata": {},
   "source": [
    "## Initialize the SPEED model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89c679-0694-444d-8e5c-1682afe91faf",
   "metadata": {},
   "source": [
    "Initialize the model with spatial data.\n",
    "\n",
    "`is_spatial` is set to `True` during the second stage of training on spatial data.\n",
    "\n",
    "`k_degree` is the degree of spatial neighbor used for spatial relative position encoding. For data with a 50 μm resolution, k is defaulted to 5. For data with a 20 μm resolution, k is recommanded to 12.\n",
    "\n",
    "`adata_sc` is set to `None` when training without prior information from single-cell data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bdac633-29fe-4e7b-a4ef-0316b22813a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix ready...\n",
      "use 0-1 matrix...\n",
      "cell_features ready...\n",
      "peak features ready...\n",
      "Without single-cell reference\n"
     ]
    }
   ],
   "source": [
    "speed = SPEED.SPEED(adata,image=None, is_spatial=True,k_degree=12, adata_sc=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7141f93-555c-4484-aa0b-1b4c12faee0f",
   "metadata": {},
   "source": [
    "### Spliting training and validation sets.\n",
    "\n",
    "`num_workers` is the number of subprocesses for data loading (default = 4).\n",
    "\n",
    "`data_type` sets the input data format used by SPEED. SPEED will handle this format internally, so no external action is required from the user. For lower GPU memory and faster training, it is recommended to set `dense = False` (default) when training on GPU, and `dense = True` when training on CPU.\n",
    "\n",
    "`batch_size_cell` and `batch_size_peak` are the batch sizes at the cell-level and peak-level. SPEED will choose automatically according to dataset size, but if the batch size is too large for your GPU, you can reduce it manually.\n",
    "\n",
    "`split_ratio` sets the proportion of the validation set at both the cell level and peak level. (default = [1/6, 1/6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211cef5a-e4b3-4b18-9d4d-bed06585bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size_cell = 1024, batch_size_peak = 32768\n",
      "split ready...\n",
      "labels ready...\n",
      "peak embedding is given\n",
      "dataset ready...\n"
     ]
    }
   ],
   "source": [
    "speed.setup_data(num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c034c-7082-451c-9877-0c74fc680094",
   "metadata": {},
   "source": [
    "### Build the neural network model for SPEED.\n",
    "\n",
    "`emb_features` is the number of embedding features (default = 32).\n",
    "\n",
    "`dropout_p` is the dropout probability of the model. For spatial data training, `dropout_p` is recommended to 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91694c79-1418-46f6-b542-73e77cb9b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed.build_model(emb_features=32,dropout_p=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd35020-ceab-4824-82eb-1e2a0b115afd",
   "metadata": {},
   "source": [
    "## Train the SPEED model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820a14c-72fb-438d-98ec-352a2c6626d2",
   "metadata": {},
   "source": [
    "`lr` is the learning rate. `device` specifies whether to train with GPU or CPU.\n",
    "\n",
    "`epoch_num` is the maximum number of training epochs (default = 500). If no improvement is observed on the validation set within `epo_max` epochs, training is considered converged and will stop (default `epo_max=30`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e29e6-eaba-4cfd-91bc-84fa2ad011f8",
   "metadata": {},
   "source": [
    "`alpha` represents the weight of the constraint on the similarity between peak embeddings of spatial data. The default value is 10. A larger `alpha` means the model relies more on single-cell prior information. \n",
    "\n",
    "`beta` represents the importance of image information for spot embedding. The default value is 1. A larger `beta` means the model relies more on image information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3f121-e88b-4ca4-8a2f-504c778472c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "speed.train(lr=1e-5, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba11e5-ed6d-4283-80ac-8cd7cca98b3a",
   "metadata": {},
   "source": [
    "## Get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d9113-3401-4872-9cf1-2b7e9e915071",
   "metadata": {},
   "source": [
    "Use `SPEED.SPEED.get_embedding` to get the low-dimensional embedding.\n",
    "\n",
    "The spot/cell embeddings will be stored in `adata.obsm['X_SPEED']`. The peak embeddings will be stored in `adata.varm['peak_SPEED']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b092afb-0c39-4e0c-913d-c0951004c87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = speed.get_embedding(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c07bd-8512-4f42-90ec-eff3aaa57c5a",
   "metadata": {},
   "source": [
    "Use `SPEED.SPEED.get_denoise_result` to get the denoised matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8572f719-a98e-45af-8bc4-bd7965530e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = speed.get_denoise_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acffa79c-983c-4e83-b90a-0a317867f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9370/9370 [00:29<00:00, 313.07it/s]\n",
      "100%|██████████| 245219/245219 [01:27<00:00, 2797.61it/s]\n"
     ]
    }
   ],
   "source": [
    "adata = speed.binarize(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0452104-ec01-4ced-aebc-413fd8a9f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(f'H3K27ac_out/adata_speed.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "610b9cac-a78b-4de9-bc7d-e4238cc75a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d9ab6-9777-4bd5-80fb-d5734ba3e196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37-speed",
   "language": "python",
   "name": "python37-speed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
